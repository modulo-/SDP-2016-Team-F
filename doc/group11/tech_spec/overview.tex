\section{Architectural Overview}

The core control of the robot was split across an external PC and the onboard
Arduino Xino RF unit. An analog video feed with a top-down perspective of the
pitch was supplied to the external PC. The external PC is able to communicate
via a supplied radio frequency link. The PC uses a USB RF device, while the
Arduino has an inbuilt RF transmitter and receiver.

The external PC is responsible for all decision making, while the Arduino
carries out instructions passed to it as quickly and accurately as possible.
To begin with, the PC listens for new frames from the video input, and
processes these to extract a set of coordinates for objects of interest: The
robots (which are detected by their coloured top-plates), and the ball. This is
used to update in internal model of the world. A few adjustments are made to
smooth over misdetections by the vision system and correct positions to account
for the fact that the robot top-plates are elevated.

At set intervals, the planning module runs, and takes a snapshot of the current
world state. It then determines what course of action to take in the current
situation, and what concrete instructions should be sent to the robot. These
instructions are then encoded into the instruction ABI, and transmitted via the
RF link (see \cref{comms} for more details). Finally, the Arduino receives the
instructions and sets the outputs to the motors and the kickers accordingly.
Some amount of feedback from the rotary encoders on the motors allows the
Arduino to adjust the motor powers on the fly, to correct its movement. The
Arduino determines itself when an instruction is over, and proceeds with the
next one, or, if no instructions are left, remains idle.

\subsection{Interaction of PC Components}

Since the controlling PC runs the vision, planning, and communications
components, their interaction is non-trivial. The entry point for the control
unit is a single main file, \texttt{main.py}, which accepts various parameters,
documented in \cref{params}. This first starts the vision subsystem in its own
thread, and registers a hook for receiving new world states. These world states
are generated by the vision, and then passed back to the main control unit,
which uses them to update its own current world state. Instead of immediately
taking the values supplied by the vision, they are first post-processed to
ensure that the values received are sensible. For example, a heuristic is used
to filter out a detection of the ball several meters from its last known
position as sporadic (It should be noted, however, that this will eventually
switch to recognising the new position of the ball, allowing actual sudden
movements to automatically correct themselves). Finally, the updated values are
inserted into the main controls own model of the world, which is more fleshed
out than that of the vision subsystem.

The planning runs on a stop-and-go mechanism. The planner is run, which sends 
appropriate instructions to the robot. Then, the planner waits a specific
amount of time, which depends on the instructions it sent, and repeats. This
loop runs in a separate thread as well. Finally, the planner requires human
input for information about the game. In particular, it needs to know whether
the game is currently in normal play, waiting for a kickoff (and by which
team), waiting for a penalty shot (and by which team), or stopped. For this
purpose, a GUI is displayed to the operator, with buttons to select each of
these states. Upon starting, the game state is considered to be stopped.
